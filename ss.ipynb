{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from langchain_community.retrievers import BM25Retriever # Import is still needed for loading\n",
    "\n",
    "# Define the file path where the retriever is saved\n",
    "file_path = \"bm25_retriever.pkl\"\n",
    "\n",
    "# Load the BM25Retriever using pickle\n",
    "with open(file_path, \"rb\") as f:\n",
    "    loaded_bm25_retriever = pickle.load(f)\n",
    "\n",
    "print(f\"BM25Retriever loaded from {file_path}\")\n",
    "\n",
    "# You can now use the loaded_bm25_retriever\n",
    "# query = \"lazy dog\"\n",
    "query = \"Explain PopularityAdjusted Block Model (PABM)\"\n",
    "relevant_docs = loaded_bm25_retriever.invoke(query)\n",
    "for doc in relevant_docs:\n",
    "    print(doc.page_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9035683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up environment variables for LM Studio\n",
    "import os\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://localhost:1234/v1/\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd79df46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/my-experiments/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Set up a LangChain pipeline with prompt template and LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# choose model name exactly as LM Studio exposes it (check LM Studio UI)\n",
    "# llm = ChatOpenAI(model=\"qwen/qwen3-4b-thinking-2507\", temperature=0.2)  \n",
    "\n",
    "llm = ChatOpenAI(model=\"qwen/qwen3-4b-2507\", temperature=0)  \n",
    "\n",
    "\n",
    "template = \"Answer the Question based on the context below.\\n\\nContext: {context}\\n\\nQ: {question}\\nA:\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# prompt = PromptTemplate(input_variables=[\"q\"], template=\"Context: Q: {q}\\nA:\")\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# print(chain.run(\"Explain recursion in 2 sentences.\"))\n",
    "\n",
    "# print(chain.invoke({\"context\": relevant_docs, \"question\": \"Explain PopularityAdjusted Block Model (PABM)\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbac9994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:{'messages': [HumanMessage(content='who are you?', additional_kwargs={}, response_metadata={}, id='8bf68ca0-152f-45f0-ba63-dbd08e8b70ff'), AIMessage(content='I am an AI assistant designed to help you with your queries. I can provide information, assist with tasks, and engage in conversations. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 181, 'total_tokens': 216, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen/qwen3-4b-2507', 'system_fingerprint': 'qwen/qwen3-4b-2507', 'id': 'chatcmpl-522mewzpyeg5gf4gb4lmad', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--76215a00-a7df-4e59-9c1b-eb75b8ff475d-0', usage_metadata={'input_tokens': 181, 'output_tokens': 35, 'total_tokens': 216, 'input_token_details': {}, 'output_token_details': {}})]}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "##------------------------------------------------------------------------------##\n",
    "\n",
    "# pip install -qU \"langchain[anthropic]\" to call the model\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# def get_weather(city: str) -> str:\n",
    "#     \"\"\"Get weather for a given city.\"\"\"\n",
    "#     return f\"It's always sunny in {city}!\"\n",
    "\n",
    "def retrieve_context(query: str) -> str:\n",
    "    \"\"\"Retrieve context for a given query using the loaded BM25Retriever.\"\"\"\n",
    "    docs = loaded_bm25_retriever.invoke(query)\n",
    "    return \"\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[retrieve_context],\n",
    "    system_prompt=\"You are a helpful assistant. you have access to a tool that retrieves relevant context based on user queries.\",\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "sl = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"who are you?\"}]}\n",
    ")\n",
    "\n",
    "print(\"Agent Response:{}\".format(sl))\n",
    "import json\n",
    "print(type(sl))\n",
    "\n",
    "\n",
    "# pretty_json_string = json.dumps(sl, indent=4)\n",
    "# print(pretty_json_string)\n",
    "\n",
    "##------------------------------------------------------------------------------##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "852f4c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='who are you?', additional_kwargs={}, response_metadata={}, id='8bf68ca0-152f-45f0-ba63-dbd08e8b70ff'),\n",
       "  AIMessage(content='I am an AI assistant designed to help you with your queries. I can provide information, assist with tasks, and engage in conversations. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 181, 'total_tokens': 216, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen/qwen3-4b-2507', 'system_fingerprint': 'qwen/qwen3-4b-2507', 'id': 'chatcmpl-522mewzpyeg5gf4gb4lmad', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--76215a00-a7df-4e59-9c1b-eb75b8ff475d-0', usage_metadata={'input_tokens': 181, 'output_tokens': 35, 'total_tokens': 216, 'input_token_details': {}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e52e028b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am an AI assistant designed to help you with your queries. I can provide information, assist with tasks, and engage in conversations. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 181, 'total_tokens': 216, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen/qwen3-4b-2507', 'system_fingerprint': 'qwen/qwen3-4b-2507', 'id': 'chatcmpl-522mewzpyeg5gf4gb4lmad', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--76215a00-a7df-4e59-9c1b-eb75b8ff475d-0', usage_metadata={'input_tokens': 181, 'output_tokens': 35, 'total_tokens': 216, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl.get('messages')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032a59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Debanjan! How can I assist you today? üòä\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The **Popularity-Adjusted Block Model (PABM)** is a probabilistic model for graph clustering that extends traditional models like the Stochastic Block Model (SBM) and the Degree-Corrected Block Model (DCBM). Here's a clear summary of PABM based on the provided context:\n",
      "\n",
      "### Key Features of PABM:\n",
      "1. **Intra- and Inter-Cluster Popularity Parameters**:\n",
      "   - Unlike SBM, which assumes uniform vertex degrees, and DCBM, which applies uniform degree corrections across clusters, PABM introduces **separate popularity parameters** for intra-cluster and inter-cluster connections.\n",
      "   - These popularity parameters, denoted as $ \\lambda_{ia} $, control the likelihood of edges between vertices within or across clusters.\n",
      "\n",
      "2. **Edge Probabilities**:\n",
      "   - The probability of an edge between vertices $ i $ and $ j $ depends on their cluster memberships and the popularity parameters.\n",
      "   - Specifically, the edge probability is modeled as a function of the popularity parameters and a connectivity matrix $ B $, which captures the structure of connections between clusters.\n",
      "\n",
      "3. **Richer Structural Model**:\n",
      "   - PABM allows for **heterogeneous connectivity patterns**‚Äîvertices in different clusters can have different degrees and connection tendencies.\n",
      "   - This captures real-world network behavior where nodes in a community may have distinct connectivity patterns.\n",
      "\n",
      "4. **Spectral Properties**:\n",
      "   - The expected adjacency matrix of a PABM has a rank between $ k $ and $ k^2 $, where $ k $ is the number of clusters.\n",
      "   - This implies that traditional spectral clustering methods, which rely on the top $ k $ eigenvectors, may fail to capture the full structure of the network.\n",
      "\n",
      "5. **Cluster Recovery**:\n",
      "   - A key theoretical result is that **cluster recovery is possible even when traditional edge-density signals vanish**, provided the intra- and inter-cluster popularity coefficients differ.\n",
      "   - This highlights a new dimension of separability: local differences in connectivity (due to popularity) can enhance clustering performance independently of global edge density.\n",
      "\n",
      "6. **Algorithm for Clustering**:\n",
      "   - The paper introduces a method called **Greedy Subspace Projection Clustering (gspc)**, which:\n",
      "     - Computes an adjacency spectral embedding into a low-dimensional space (dimension $ d $, typically $ k^2 $).\n",
      "     - For each cluster, estimates a subspace via singular value decomposition (SVD) of node embeddings.\n",
      "     - Reassigns nodes to the cluster that minimizes projection error (i.e., the distance between a node's embedding and its projection onto the cluster's subspace).\n",
      "   - This approach outperforms traditional spectral clustering, especially in complex, heterogeneous networks.\n",
      "\n",
      "7. **Optimal Error Rate**:\n",
      "   - The paper characterizes the **optimal error rate** for clustering under PABM, showing that it can be lower than in SBM or DCBM when intra- and inter-cluster popularity differences are present.\n",
      "\n",
      "### Why PABM Matters:\n",
      "- It addresses limitations of existing models by capturing **local degree heterogeneity** and **popularity differences** within and across clusters.\n",
      "- It enables better clustering performance in networks where traditional edge-density signals are weak or absent.\n",
      "- It provides a more realistic model for real-world networks (e.g., social, biological, or communication networks) where node popularity and local connectivity vary significantly.\n",
      "\n",
      "### In Summary:\n",
      "PABM is a powerful extension of traditional graph models that allows for **fine-grained control over node popularity and connectivity patterns**. Its ability to recover clusters even when edge density signals vanish makes it particularly useful for complex, real-world networks where traditional methods may fail. The use of spectral embeddings with $ k^2 $ eigenvectors further improves clustering accuracy in such settings.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The **Model Structure and Assumptions** of the **Popularity-Adjusted Block Model (PABM)** are as follows:\n",
      "\n",
      "---\n",
      "\n",
      "### üìå 1. **Graph Structure**\n",
      "- The network consists of $ n $ vertices partitioned into $ k \\geq 2 $ disjoint clusters (or blocks).\n",
      "- The interaction between vertices is represented by an undirected adjacency matrix $ A \\in \\{0,1\\}^{n \\times n} $, where $ A_{ij} $ indicates the presence (1) or absence (0) of an edge between vertices $ i $ and $ j $.\n",
      "\n",
      "---\n",
      "\n",
      "### üìå 2. **Latent Block Structure**\n",
      "- Each vertex $ i $ is assigned a latent label $ z_i^* \\in [k] $, indicating which cluster it belongs to.\n",
      "- The full cluster assignment is represented by the vector $ \\mathbf{z}^* = (z_1^*, \\dots, z_n^*) \\in [k]^n $.\n",
      "\n",
      "---\n",
      "\n",
      "### üìå 3. **Edge Probabilities in PABM**\n",
      "- The probability of an edge between vertices $ i $ and $ j $, given their cluster memberships $ z_i^* $ and $ z_j^* $, is modeled as:\n",
      "  $$\n",
      "  \\mathbb{P}(A_{ij} = 1 \\mid z_i^*, z_j^*) = \\begin{cases}\n",
      "    \\lambda_{i a} \\lambda_{j b} B_{ab}, & \\text{if } z_i^* = a, z_j^* = b \\\\\n",
      "    0, & \\text{otherwise}\n",
      "  \\end{cases}\n",
      "  $$\n",
      "- Here:\n",
      "  - $ \\lambda_{i a} $: **Popularity parameter** for vertex $ i $ in cluster $ a $ (intra-cluster popularity).\n",
      "  - $ B_{ab} $: Connectivity matrix between clusters $ a $ and $ b $, where $ B_{aa} $ controls intra-cluster connections and $ B_{ab} $ (for $ a \\ne b $) controls inter-cluster connections.\n",
      "  - The model assumes that $ \\lambda_{i a} $ and $ B_{ab} $ are constants (independent of $ n $), satisfying Assumption 1.\n",
      "\n",
      "---\n",
      "\n",
      "### üìå 4. **Key Assumptions**\n",
      "1. **Constant Popularity and Connectivity Parameters**:\n",
      "   - All parameters $ B_{ab} $ and $ \\lambda_{ia} $ are **independent of $ n $** (i.e., they do not scale with network size).\n",
      "   - This ensures the model is well-defined in the large-$ n $ limit.\n",
      "\n",
      "2. **Sparsity Control**:\n",
      "   - The parameter $ \\rho_n $ controls the average degree of the graph. The average degree scales as $ n \\rho_n $, and the model assumes $ \\rho_n \\to 0 $ as $ n \\to \\infty $ (i.e., the graph is sparse).\n",
      "\n",
      "3. **Symmetry**:\n",
      "   - The adjacency matrix is symmetric, and the model is defined for undirected graphs.\n",
      "\n",
      "4. **Intra- and Inter-Cluster Popularity Separation**:\n",
      "   - Unlike the Degree-Corrected Block Model (DCBM), which applies uniform popularity corrections, PABM allows **different popularity parameters per vertex per cluster**, enabling richer and more realistic modeling of node behavior.\n",
      "\n",
      "---\n",
      "\n",
      "### üìå 5. **Spectral Properties**\n",
      "- The expected adjacency matrix of the PABM has a **rank between $ k $ and $ k^2 $**.\n",
      "- This implies that traditional spectral clustering (which uses only the top $ k $ eigenvectors) may **fail to capture the full structure** of the network.\n",
      "- Instead, **using up to $ k^2 $ eigenvectors** (e.g., in the greedy subspace projection method) is more effective.\n",
      "\n",
      "---\n",
      "\n",
      "### üìå 6. **Cluster Recovery and Hardness**\n",
      "- A key theoretical result: **Cluster recovery is possible even when traditional edge-density signals vanish**, provided the intra- and inter-cluster popularity coefficients differ.\n",
      "- This shows that **local differences in connectivity patterns** (captured by popularity) can enhance cluster separability independently of global edge density.\n",
      "\n",
      "---\n",
      "\n",
      "### ‚úÖ Summary of Key Assumptions:\n",
      "| Assumption | Description |\n",
      "|----------|-------------|\n",
      "| **Constant parameters** | $ B_{ab} $, $ \\lambda_{ia} $ are constant (independent of $ n $) |\n",
      "| **Sparsity** | Average degree scales as $ n \\rho_n $, with $ \\rho_n \\to 0 $ |\n",
      "| **Symmetry** | Undirected graph (symmetric adjacency matrix) |\n",
      "| **Separate popularity** | Intra- and inter-cluster popularity parameters are distinct and non-uniform |\n",
      "| **Rank of adjacency matrix** | Expected rank between $ k $ and $ k^2 $, requiring $ k^2 $ eigenvectors for full structure |\n",
      "\n",
      "---\n",
      "\n",
      "This structure makes PABM more flexible and realistic than SBM or DCBM, especially for networks where node popularity and local connectivity vary significantly. It also provides a stronger foundation for understanding the limits of clustering in complex, sparse networks.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is **Debanjan**. üòä\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver \n",
    "\n",
    "# def get_weather(city: str) -> str:\n",
    "#     \"\"\"Get weather for a given city.\"\"\"\n",
    "#     return f\"It's always sunny in {city}!\"\n",
    "\n",
    "def retrieve_context(query: str) -> str:\n",
    "    \"\"\"Retrieve context for a given query using the loaded BM25Retriever.\"\"\"\n",
    "\n",
    "    file_path = \"bm25_retriever.pkl\"\n",
    "\n",
    "    # Load the BM25Retriever using pickle\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        loaded_bm25_retriever = pickle.load(f)\n",
    "    docs = loaded_bm25_retriever.invoke(query)\n",
    "    return \"\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[retrieve_context],\n",
    "    system_prompt=\"You are a helpful assistant. you have access to a tool that retrieves relevant context based on user queries.\",\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "sl = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Summarize Our Conversation\"}]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
    ")\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "final_response = agent.invoke({\"messages\": \"hi, my name is Debanjan\"}, config)\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\n",
    "final_response = agent.invoke({\"messages\": \"Explain PopularityAdjusted Block Model (PABM)\"}, config)\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\n",
    "final_response = agent.invoke({\"messages\": \"Explain Model Structure and Assumptions\"}, config)\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# print(\"Agent Response:{}\".format(sl))\n",
    "\n",
    "# response = sl.get('messages')[-1]\n",
    "\n",
    "# print(\"------------------------------\")\n",
    "# print(\"Agent Response:{}\".format(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ade23001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Summarize Our Conversation', additional_kwargs={}, response_metadata={}, id='a55ed2bd-c811-4e75-8aee-aba72b54eca5'),\n",
       "  AIMessage(content=\"We have not had a prior conversation, and no specific content has been discussed yet. If you'd like to discuss a topic or retrieve information on a specific query, please let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 182, 'total_tokens': 221, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen/qwen3-4b-2507', 'system_fingerprint': 'qwen/qwen3-4b-2507', 'id': 'chatcmpl-zy6uzt738vkijmg7zeili', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5004e7ea-d8ae-444e-858d-cee37313f8d9-0', usage_metadata={'input_tokens': 182, 'output_tokens': 39, 'total_tokens': 221, 'input_token_details': {}, 'output_token_details': {}}),\n",
       "  HumanMessage(content='hi, my name is Debanjan', additional_kwargs={}, response_metadata={}, id='990ccd8d-bcf4-4961-bef4-686aa8aa8b89'),\n",
       "  AIMessage(content='Hi Debanjan! How can I assist you today? üòä', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 238, 'total_tokens': 253, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen/qwen3-4b-2507', 'system_fingerprint': 'qwen/qwen3-4b-2507', 'id': 'chatcmpl-2x7yp7yuqix2pbtl21ibgf', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--617191a8-ee17-4765-95b2-66c2a1ccc888-0', usage_metadata={'input_tokens': 238, 'output_tokens': 15, 'total_tokens': 253, 'input_token_details': {}, 'output_token_details': {}}),\n",
       "  HumanMessage(content='Explain PopularityAdjusted Block Model (PABM)', additional_kwargs={}, response_metadata={}, id='7ee24c9d-1d93-42e6-b3dd-748f35917477'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 274, 'total_tokens': 303, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen/qwen3-4b-2507', 'system_fingerprint': 'qwen/qwen3-4b-2507', 'id': 'chatcmpl-r0tskdceodq35j9r6ptpm', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--bcd4c024-8f30-4d22-a703-caf800756d55-0', tool_calls=[{'name': 'retrieve_context', 'args': {'query': 'PopularityAdjusted Block Model (PABM)'}, 'id': '234278182', 'type': 'tool_call'}], usage_metadata={'input_tokens': 274, 'output_tokens': 29, 'total_tokens': 303, 'input_token_details': {}, 'output_token_details': {}}),\n",
       "  ToolMessage(content='## Optimal Graph Clustering without Edge Density Signals\\n\\nMaximilien Dreveton EPFL\\n\\nmaximilien.dreveton@epfl.ch\\n\\nMatthias Grossglauser EPFL\\n\\nmatthias.grossglauser@epfl.ch\\n\\n## Abstract\\n\\nThis paper establishes the theoretical limits of graph clustering under the PopularityAdjusted Block Model (PABM), addressing limitations of existing models. In contrast to the Stochastic Block Model (SBM), which assumes uniform vertex degrees, and to the Degree-Corrected Block Model (DCBM), which applies uniform degree corrections across clusters, PABM introduces separate popularity parameters for intra- and inter-cluster connections. Our main contribution is the characterization of the optimal error rate for clustering under PABM, which provides novel insights on clustering hardness: we demonstrate that unlike SBM and DCBM, cluster recovery remains possible in PABM even when traditional edge-density signals vanish, provided intra- and inter-cluster popularity coefficients differ. This highlights a dimension of degree heterogeneity captured by PABM but overlooked by DCBM: local differences in connectivity patterns can enhance cluster separability independently of global edge densities. Finally, because PABM exhibits a richer structure, its expected adjacency matrix has rank between k and k 2 , where k is the number of clusters. As a result, spectral embeddings based on the top k eigenvectors may fail to capture important structural information. Our numerical experiments on both synthetic and real datasets confirm that spectral clustering algorithms incorporating k 2 eigenvectors outperform traditional spectral approaches.\\n## 2 Optimal Error Rate in Popularity-Adjusted Block Models\\n\\n## 2.1 Model Definition and Parameter Space\\n\\nWe consider n vertices partitioned into k ‚â• 2 disjoint blocks. The partition is encoded by a vertexlabeling vector z ‚àó = ( z ‚àó 1 , ¬∑ ¬∑ ¬∑ , z ‚àó n ) ‚àà [ k ] n so that z ‚àó i indicates the cluster of vertex i . These n vertices interact pairwise, giving rise to undirected edges, and these pairwise interactions are grouped by a symmetric matrix A ‚àà { 0 , 1 } n √ó n called the adjacency matrix. The Popularity Adjusted Block Model supposes that, conditionally on the block structure, the upper-diagonal elements ( A ij ) i&gt;j are independent Bernoulli random variables such that, conditionally on z ‚àó i and z ‚àó j ,\\n\\n<!-- formula-not-decoded -->\\n\\nwhere ( Œª ia ) i ‚àà [ n ] ,a ‚àà [ k ] are the popularity parameters and B ‚àà R k √ó k + is the connectivity matrix across clusters. The parameter œÅ n controls the graph sparsity, as the average degree is of order nœÅ n when the following assumption is made.\\n\\nAssumption 1. The quantities B ab and Œª ia are constant (so they do not scale with n ) for all i ‚àà [ n ] and a, b ‚àà [ k ] .\\n\\nGiven a realization of a PABM, we aim to infer the latent block structure z ‚àó . Let ÀÜ z = ÀÜ z ( A ) be an estimate of z ‚àó , and define the clustering error as\\n\\n<!-- formula-not-decoded -->\\n\\nwhere Sym( k ) is the set of permutations of [ k ] and Ham( ¬∑ , ¬∑ ) is the Hamming distance. We are interested in the expected loss of an estimator, namely E [loss( z ‚àó , ÀÜ z ( A ))] , where the expectation is taken with respect to the random variable A sampled from (2.1).\\n\\n## 2.2 A Key Information-Theoretic Divergence\\nThe algorithm from Bhadra et al. (2025) is an iterative community detection method designed for the Popularity-Adjusted Block Model (PABM). It begins by computing an adjacency spectral embedding of the network into a low-dimensional space of dimension d (where typically d = k 2 ). For each tentative community, a subspace is estimated via singular value decomposition of the node embeddings in that cluster. The algorithm then greedily reassigns nodes to the community whose subspace yields the smallest projection error, thereby minimizing the objective function. This process iterates until node assignments stabilize, yielding a community structure tailored to the PABM. Although the original paper does not assign a name to the algorithm, we refer to it as Greedy Subspace Projection Clustering ( gspc ). Algorithm 6 provides the pseudo-code.\\n\\n## Algorithm 6: Greedy Subspace Projection Clustering ( gspc )\\n\\n```\\nInput: Adjacency matrix A ‚àà R n √ó n , number of communities K , embedding dimension d (default: d = k 2 ), initial cluster labels z (0) ‚àà [ k ] n Output: Final cluster labels ÀÜ z ‚àà [ k ] n 1 Compute adjacency spectral embedding X ‚àà R n √ó d from A ; 2 Initialize cluster labels ÀÜ z ‚Üê z (0) ; 3 repeat 4 for k ‚Üê 1 to K do 5 Extract X k ‚Üê{ x i : ‚Ñì i = k } ; 6 Compute leading d left singular vectors U k of X k ; 7 for i ‚Üê 1 to n do 8 for k ‚Üê 1 to K do 9 Compute projection loss L ik ‚Üê‚à• x i -U k U ‚ä§ k x i ‚à• 2 ; 10 Update ÀÜ z i ‚Üê arg min k L ik ; 11 until no label changes or maximum iterations reached ; 12 return ÀÜ z ;\\nÃ∏\\n\\nand we recover the instance-optimal error rate in SBM with inhomogeneous interactions (Yun and Prouti√®re, 2016). Finally, the Chernoff-Hellinger divergence has a simple expression in the case of homogeneous interactions. Indeed, when B ab = p 0 1 ( a = b ) + q 0 1 ( a = b ) and the clusters are of equal-size ( œÄ a = 1 /k ), the divergence simplifies to min a = b ‚àà [ k ] CH AS ( a, b ) = nœÅ n k ( ‚àö p 0 - ‚àö q 0 ) 2 .\\n\\nÃ∏\\n\\nÃ∏\\n\\nDegree-Corrected Block Model Suppose that Œª iz ‚àó j = Œ∏ i , so that the PABM boils down to a DCBM with homogeneous interactions in which P ij = Œ∏ i Œ∏ j B z ‚àó i z ‚àó j œÅ n . For the simplicity of the discussion, we consider cluster of equal-size ( i.e., œÄ a = 1 /k for all a ‚àà [ k ] ), and homogeneous interactions ( i.e., B ab = p 0 1 { a = b } + q 0 1 { a = b } ). Consider a vertex i in a cluster z ‚àó i and let a ‚àà [ k ] \\\\{ z ‚àó i } . We have ‚àÜ( i, a ) = Œ∏ i nœÅ n k ( ‚àö p 0 - ‚àö q 0 ) 2 , where we used ‚àë i : z ‚àó i = a Œ∏ i = 1 . Thus, we recover the asymptotic optimal error-rate 1 n ‚àë i e -Œ∏ i nœÅn k ( ‚àö p 0 - ‚àö q 0 ) 2 established in Gao et al. (2018).\\n\\n## 2.5 Optimal Error Rate in Homogeneous PABM\\n\\nÃ∏\\n\\nWe now show how Theorems 1 and 2, when applied to PABM, reveal novel phenomena. Suppose B ab = p 0 1 { a = b } + q 0 1 { a = b } and Œª ia = Œª in i 1 { z ‚àó i = a } + Œª out i 1 { z ‚àó i = a } . We have\\n\\nÃ∏\\n\\nÃ∏\\n\\n<!-- formula-not-decoded -->\\n\\nProposition 3. Consider a PABM with homogeneous interactions with p 0 q 0 &gt; 0 , and k equal-size communities. Suppose that Œª out 1 = ¬∑ ¬∑ ¬∑ = Œª out n = 1 and that the coefficients Œª in 1 , ¬∑ ¬∑ ¬∑ , Œª in n are sampled iid from Uni(1 -c, 1 + c ) with c ‚àà (0 , 1) . Denote Œ≥ c = 1 3 c ( (1 + c ) 3 / 2 -(1 -c ) 3 / 2 ) . We have\\n\\n<!-- formula-not-decoded -->\\n\\nwhere\\n\\n<!-- formula-not-decoded -->\\n\\n<!-- formula-not-decoded -->', name='retrieve_context', id='88e5628e-b265-4e04-bed0-bab3148ce6dc', tool_call_id='234278182'),\n",
       "  AIMessage(content=\"The **Popularity-Adjusted Block Model (PABM)** is a probabilistic model for graph clustering that extends traditional models like the Stochastic Block Model (SBM) and the Degree-Corrected Block Model (DCBM). Here's a clear summary of PABM based on the provided context:\\n\\n### Key Features of PABM:\\n1. **Intra- and Inter-Cluster Popularity Parameters**:\\n   - Unlike SBM, which assumes uniform vertex degrees, and DCBM, which applies uniform degree corrections across clusters, PABM introduces **separate popularity parameters** for intra-cluster and inter-cluster connections.\\n   - These popularity parameters, denoted as $ \\\\lambda_{ia} $, control the likelihood of edges between vertices within or across clusters.\\n\\n2. **Edge Probabilities**:\\n   - The probability of an edge between vertices $ i $ and $ j $ depends on their cluster memberships and the popularity parameters.\\n   - Specifically, the edge probability is modeled as a function of the popularity parameters and a connectivity matrix $ B $, which captures the structure of connections between clusters.\\n\\n3. **Richer Structural Model**:\\n   - PABM allows for **heterogeneous connectivity patterns**‚Äîvertices in different clusters can have different degrees and connection tendencies.\\n   - This captures real-world network behavior where nodes in a community may have distinct connectivity patterns.\\n\\n4. **Spectral Properties**:\\n   - The expected adjacency matrix of a PABM has a rank between $ k $ and $ k^2 $, where $ k $ is the number of clusters.\\n   - This implies that traditional spectral clustering methods, which rely on the top $ k $ eigenvectors, may fail to capture the full structure of the network.\\n\\n5. **Cluster Recovery**:\\n   - A key theoretical result is that **cluster recovery is possible even when traditional edge-density signals vanish**, provided the intra- and inter-cluster popularity coefficients differ.\\n   - This highlights a new dimension of separability: local differences in connectivity (due to popularity) can enhance clustering performance independently of global edge density.\\n\\n6. **Algorithm for Clustering**:\\n   - The paper introduces a method called **Greedy Subspace Projection Clustering (gspc)**, which:\\n     - Computes an adjacency spectral embedding into a low-dimensional space (dimension $ d $, typically $ k^2 $).\\n     - For each cluster, estimates a subspace via singular value decomposition (SVD) of node embeddings.\\n     - Reassigns nodes to the cluster that minimizes projection error (i.e., the distance between a node's embedding and its projection onto the cluster's subspace).\\n   - This approach outperforms traditional spectral clustering, especially in complex, heterogeneous networks.\\n\\n7. **Optimal Error Rate**:\\n   - The paper characterizes the **optimal error rate** for clustering under PABM, showing that it can be lower than in SBM or DCBM when intra- and inter-cluster popularity differences are present.\\n\\n### Why PABM Matters:\\n- It addresses limitations of existing models by capturing **local degree heterogeneity** and **popularity differences** within and across clusters.\\n- It enables better clustering performance in networks where traditional edge-density signals are weak or absent.\\n- It provides a more realistic model for real-world networks (e.g., social, biological, or communication networks) where node popularity and local connectivity vary significantly.\\n\\n### In Summary:\\nPABM is a powerful extension of traditional graph models that allows for **fine-grained control over node popularity and connectivity patterns**. Its ability to recover clusters even when edge density signals vanish makes it particularly useful for complex, real-world networks where traditional methods may fail. The use of spectral embeddings with $ k^2 $ eigenvectors further improves clustering accuracy in such settings.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 773, 'prompt_tokens': 2117, 'total_tokens': 2890, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen/qwen3-4b-2507', 'system_fingerprint': 'qwen/qwen3-4b-2507', 'id': 'chatcmpl-3w9kxmobafamkfav61w5c', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d0381003-e7d1-439d-9865-6b53ca27b6ed-0', usage_metadata={'input_tokens': 2117, 'output_tokens': 773, 'total_tokens': 2890, 'input_token_details': {}, 'output_token_details': {}}),\n",
       "  HumanMessage(content='Model Structure and Assumptions', additional_kwargs={}, response_metadata={}, id='0da1ed64-4a44-4255-bff7-5c6f4ddf6362'),\n",
       "  AIMessage(content='The **Model Structure and Assumptions** of the **Popularity-Adjusted Block Model (PABM)** are as follows:\\n\\n---\\n\\n### üìå 1. **Graph Structure**\\n- The network consists of $ n $ vertices partitioned into $ k \\\\geq 2 $ disjoint clusters (or blocks).\\n- The interaction between vertices is represented by an undirected adjacency matrix $ A \\\\in \\\\{0,1\\\\}^{n \\\\times n} $, where $ A_{ij} $ indicates the presence (1) or absence (0) of an edge between vertices $ i $ and $ j $.\\n\\n---\\n\\n### üìå 2. **Latent Block Structure**\\n- Each vertex $ i $ is assigned a latent label $ z_i^* \\\\in [k] $, indicating which cluster it belongs to.\\n- The full cluster assignment is represented by the vector $ \\\\mathbf{z}^* = (z_1^*, \\\\dots, z_n^*) \\\\in [k]^n $.\\n\\n---\\n\\n### üìå 3. **Edge Probabilities in PABM**\\n- The probability of an edge between vertices $ i $ and $ j $, given their cluster memberships $ z_i^* $ and $ z_j^* $, is modeled as:\\n  $$\\n  \\\\mathbb{P}(A_{ij} = 1 \\\\mid z_i^*, z_j^*) = \\\\begin{cases}\\n    \\\\lambda_{i a} \\\\lambda_{j b} B_{ab}, & \\\\text{if } z_i^* = a, z_j^* = b \\\\\\\\\\n    0, & \\\\text{otherwise}\\n  \\\\end{cases}\\n  $$\\n- Here:\\n  - $ \\\\lambda_{i a} $: **Popularity parameter** for vertex $ i $ in cluster $ a $ (intra-cluster popularity).\\n  - $ B_{ab} $: Connectivity matrix between clusters $ a $ and $ b $, where $ B_{aa} $ controls intra-cluster connections and $ B_{ab} $ (for $ a \\\\ne b $) controls inter-cluster connections.\\n  - The model assumes that $ \\\\lambda_{i a} $ and $ B_{ab} $ are constants (independent of $ n $), satisfying Assumption 1.\\n\\n---\\n\\n### üìå 4. **Key Assumptions**\\n1. **Constant Popularity and Connectivity Parameters**:\\n   - All parameters $ B_{ab} $ and $ \\\\lambda_{ia} $ are **independent of $ n $** (i.e., they do not scale with network size).\\n   - This ensures the model is well-defined in the large-$ n $ limit.\\n\\n2. **Sparsity Control**:\\n   - The parameter $ \\\\rho_n $ controls the average degree of the graph. The average degree scales as $ n \\\\rho_n $, and the model assumes $ \\\\rho_n \\\\to 0 $ as $ n \\\\to \\\\infty $ (i.e., the graph is sparse).\\n\\n3. **Symmetry**:\\n   - The adjacency matrix is symmetric, and the model is defined for undirected graphs.\\n\\n4. **Intra- and Inter-Cluster Popularity Separation**:\\n   - Unlike the Degree-Corrected Block Model (DCBM), which applies uniform popularity corrections, PABM allows **different popularity parameters per vertex per cluster**, enabling richer and more realistic modeling of node behavior.\\n\\n---\\n\\n### üìå 5. **Spectral Properties**\\n- The expected adjacency matrix of the PABM has a **rank between $ k $ and $ k^2 $**.\\n- This implies that traditional spectral clustering (which uses only the top $ k $ eigenvectors) may **fail to capture the full structure** of the network.\\n- Instead, **using up to $ k^2 $ eigenvectors** (e.g., in the greedy subspace projection method) is more effective.\\n\\n---\\n\\n### üìå 6. **Cluster Recovery and Hardness**\\n- A key theoretical result: **Cluster recovery is possible even when traditional edge-density signals vanish**, provided the intra- and inter-cluster popularity coefficients differ.\\n- This shows that **local differences in connectivity patterns** (captured by popularity) can enhance cluster separability independently of global edge density.\\n\\n---\\n\\n### ‚úÖ Summary of Key Assumptions:\\n| Assumption | Description |\\n|----------|-------------|\\n| **Constant parameters** | $ B_{ab} $, $ \\\\lambda_{ia} $ are constant (independent of $ n $) |\\n| **Sparsity** | Average degree scales as $ n \\\\rho_n $, with $ \\\\rho_n \\\\to 0 $ |\\n| **Symmetry** | Undirected graph (symmetric adjacency matrix) |\\n| **Separate popularity** | Intra- and inter-cluster popularity parameters are distinct and non-uniform |\\n| **Rank of adjacency matrix** | Expected rank between $ k $ and $ k^2 $, requiring $ k^2 $ eigenvectors for full structure |\\n\\n---\\n\\nThis structure makes PABM more flexible and realistic than SBM or DCBM, especially for networks where node popularity and local connectivity vary significantly. It also provides a stronger foundation for understanding the limits of clustering in complex, sparse networks.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1094, 'prompt_tokens': 2905, 'total_tokens': 3999, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen/qwen3-4b-2507', 'system_fingerprint': 'qwen/qwen3-4b-2507', 'id': 'chatcmpl-pkajzxumzkbctb40nwhm5', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5cbe239d-643f-4081-84f7-cd7fe8ac9c59-0', usage_metadata={'input_tokens': 2905, 'output_tokens': 1094, 'total_tokens': 3999, 'input_token_details': {}, 'output_token_details': {}}),\n",
       "  HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='5e508815-9c59-4740-81f0-875e97bb22b5'),\n",
       "  AIMessage(content='Your name is **Debanjan**. üòä', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 4013, 'total_tokens': 4025, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'qwen/qwen3-4b-2507', 'system_fingerprint': 'qwen/qwen3-4b-2507', 'id': 'chatcmpl-hisacv8ua0jn5x8vk3h6sf', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--2f030abe-0db1-4f3b-aefe-ec3df4171ad4-0', usage_metadata={'input_tokens': 4013, 'output_tokens': 12, 'total_tokens': 4025, 'input_token_details': {}, 'output_token_details': {}})]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5d669eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Bob! üòä\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n================================== Ai Message ==================================\\n\\nYour name is Bob. You told me that earlier.\\nIf you'd like me to call you a nickname or use a different name, just say the word.\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.graph.message import REMOVE_ALL_MESSAGES\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents import create_agent, AgentState\n",
    "from langchain.agents.middleware import before_model\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "@before_model\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Keep only the last few messages to fit context window.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if len(messages) <= 3:\n",
    "        return None  # No changes needed\n",
    "\n",
    "    first_msg = messages[0]\n",
    "    recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]\n",
    "    new_messages = [first_msg] + recent_messages\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=REMOVE_ALL_MESSAGES),\n",
    "            *new_messages\n",
    "        ]\n",
    "    }\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[retrieve_context],\n",
    "    middleware=[trim_messages],\n",
    "    checkpointer=InMemorySaver(),\n",
    ")\n",
    "\n",
    "config: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "agent.invoke({\"messages\": \"hi, my name is bob\"}, config)\n",
    "agent.invoke({\"messages\": \"write a short poem about cats\"}, config)\n",
    "agent.invoke({\"messages\": \"now do the same but for dogs\"}, config)\n",
    "final_response = agent.invoke({\"messages\": \"what's my name?\"}, config)\n",
    "\n",
    "final_response[\"messages\"][-1].pretty_print()\n",
    "\"\"\"\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Your name is Bob. You told me that earlier.\n",
    "If you'd like me to call you a nickname or use a different name, just say the word.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43d13f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
